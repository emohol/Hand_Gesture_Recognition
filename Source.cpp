// feature extraction.cpp : Defines the entry point for the console application.
//

#include <opencv/cv.h>
#include <opencv/highgui.h>
#include <opencv/ml.h>
#include <opencv2/features2d.hpp>
#include <opencv2/highgui.hpp>
#include <opencv2/opencv.hpp>
#include <opencv2/core.hpp>
#include <opencv2/video/background_segm.hpp>
#include <opencv2/ml.hpp>
#include <opencv/highgui.h>
#include <opencv2\xfeatures2d.hpp>
#include <opencv2/videoio.hpp>
#include <opencv2\video.hpp>
#include "opencv2/imgcodecs.hpp"
#include "opencv2/imgproc.hpp"
#include <opencv2/opencv.hpp>
#include <opencv2/cvconfig.h>

#include <vector>
#include <fstream>
#include <stdio.h>
#include <iostream>
#include <sstream>


using namespace cv;
using namespace std;
using namespace cv::ml;
using namespace cv::xfeatures2d;

using std::cout;
using std::cerr;
using std::endl;
using std::vector;



bool R1(int R, int G, int B) {
	bool e1 = (R>95) && (G>40) && (B>20) && ((max(R, max(G, B)) - min(R, min(G, B)))>15) && (abs(R - G)>15) && (R>G) && (R>B);
	bool e2 = (R>220) && (G>210) && (B>170) && (abs(R - G) <= 15) && (R>B) && (G>B);
	return (e1 || e2);
}

bool R2(float Y, float Cr, float Cb) {
	bool e3 = Cr <= 1.5862*Cb + 20;
	bool e4 = Cr >= 0.3448*Cb + 76.2069;
	bool e5 = Cr >= -4.5652*Cb + 234.5652;
	bool e6 = Cr <= -1.15*Cb + 301.75;
	bool e7 = Cr <= -2.2857*Cb + 432.85;
	return e3 && e4 && e5 && e6 && e7;
}

bool R3(float H, float S, float V) {
	return (H<25) || (H > 230);
}

Mat ThresholdSkin(const Mat &src) {
	// Allocate the result matrix
	Mat dst = Mat::zeros(src.rows, src.cols, CV_8UC1);
	// We operate in YCrCb and HSV:
	Mat src_ycrcb, src_hsv;
	// OpenCV scales the YCrCb components, so that they
	// cover the whole value range of [0,255], so there's
	// no need to scale the values:
	cvtColor(src, src_ycrcb, CV_BGR2YCrCb);
	// OpenCV scales the Hue Channel to [0,180] for
	// 8bit images, make sure we are operating on
	// the full spectrum from [0,360] by using floating
	// point precision:
	src.convertTo(src_hsv, CV_32FC3);
	cvtColor(src_hsv, src_hsv, CV_BGR2HSV);
	// And then scale between [0,255] for the rules in the paper
	// to apply. This uses normalize with CV_32FC3, which may fail
	// on older OpenCV versions. If so, you probably want to split
	// the channels first and call normalize independently on each
	// channel:
	normalize(src_hsv, src_hsv, 0.0, 255.0, NORM_MINMAX, CV_32FC3);
	// Iterate over the data:
	for (int i = 0; i < src.rows; i++) {
		for (int j = 0; j < src.cols; j++) {
			// Get the pixel in BGR space:
			Vec3b pix_bgr = src.ptr<Vec3b>(i)[j];
			int B = pix_bgr.val[0];
			int G = pix_bgr.val[1];
			int R = pix_bgr.val[2];
			// And apply RGB rule:
			bool a = R1(R, G, B);
			// Get the pixel in YCrCB space:
			Vec3b pix_ycrcb = src_ycrcb.ptr<Vec3b>(i)[j];
			int Y = pix_ycrcb.val[0];
			int Cr = pix_ycrcb.val[1];
			int Cb = pix_ycrcb.val[2];
			// And apply the YCrCB rule:
			bool b = R2(Y, Cr, Cb);
			// Get the pixel in HSV space:
			Vec3f pix_hsv = src_hsv.ptr<Vec3f>(i)[j];
			float H = pix_hsv.val[0];
			float S = pix_hsv.val[1];
			float V = pix_hsv.val[2];
			// And apply the HSV rule:
			bool c = R3(H, S, V);
			// If not skin, then black
			if (a && b && c) {
				dst.at<unsigned char>(i, j) = 255;
			}
			else{
				dst.at<unsigned char>(i, j) = 0;
			}
		}
	}
	return dst;
}
// Global variables
Mat frame; //current frame
Mat fgMaskMOG2; //fg mask fg mask generated by MOG2 method
Mat fgMaskMOG; //fg mask fg mask generated by MOG method
Ptr<BackgroundSubtractor> pMOG2; //MOG2 Background subtractor
Ptr<BackgroundSubtractor> pMOG; //MOG Background subtractor
int keyboard=0; //input from keyboard


Mat pre_processing(Mat frame){


	//frame=imread("/home/ishita/1.jpg");
	//namedWindow("Frame", WINDOW_NORMAL);
	//namedWindow("FG Mask MOG 2",WINDOW_NORMAL);
	//create Background Subtractor objects
	//pMOG2 = createBackgroundSubtractorMOG2(); //MOG2 approach

	pMOG2 = createBackgroundSubtractorMOG2(); //MOG2 approach

	//imshow("Frame", frame);
	imwrite("C:/Users/Nikunj/Documents/Visual Studio 2013/Projects/new/new/frame.jpg", frame);
	// Put a little Gaussian blur on:
	GaussianBlur(frame, frame, Size(5, 5), 0, 0);
	// Filter for skin:
	Mat skin = ThresholdSkin(frame);
	// And finally perform a little dilation and erosion
	int dilation_size = 5;
	int erosion_size = 5;
	imwrite("C:/Users/Nikunj/Documents/Visual Studio 2013/Projects/new/new/skin.jpg", skin);

	dilate(skin, skin, getStructuringElement(
		MORPH_RECT,
		Size(2 * dilation_size + 1, 2 * dilation_size + 1),
		Point(dilation_size, dilation_size)));

	erode(skin, skin, getStructuringElement(
		MORPH_RECT,
		Size(2 * erosion_size + 1, 2 * erosion_size + 1),
		Point(erosion_size, erosion_size)));
	//namedWindow("skin", WINDOW_NORMAL);
	//imshow("skin", skin);
	imwrite("C:/Users/Nikunj/Documents/Visual Studio 2013/Projects/new/new/morph.jpg", skin);

	
//update the background model
	pMOG2->apply(skin, fgMaskMOG2);//fgmaskMOG2 contains the final image after skin thresholding and background subtraction
	//imshow("FG Mask MOG 2", fgMaskMOG2);
	
	imwrite("C:/Users/Nikunj/Documents/Visual Studio 2013/Projects/new/new/mask.jpg", fgMaskMOG2);
	GaussianBlur(fgMaskMOG2, fgMaskMOG2, Size(5, 5), 0, 0);
	imwrite("C:/Users/Nikunj/Documents/Visual Studio 2013/Projects/new/new/blur.jpg", skin);
	return fgMaskMOG2;




}
char ch[30];
int minHessian = 300;



//Ptr<DescriptorExtractor> extractor(new SiftDescriptorExtractor);
//SiftDescriptorExtractor detector;
//Ptr<DescriptorMatcher> matcher(new FlannBasedMatcher);
Ptr<SiftFeatureDetector> detector = SiftFeatureDetector::create();
Ptr<SiftDescriptorExtractor> extractor = SiftDescriptorExtractor::create();
Ptr<DescriptorMatcher> matcher = DescriptorMatcher::create("FlannBased");


//---dictionary size=number of cluster's centroids
int dictionarySize = 700;
TermCriteria tc(CV_TERMCRIT_ITER, 10, 0.001);
int retries = 1;
int flags = KMEANS_PP_CENTERS;
BOWKMeansTrainer bowTrainer(dictionarySize, tc, retries, flags);
BOWImgDescriptorExtractor bowDE(extractor, matcher);
//BOWImgDescriptorExtractor bowDE(detector, matcher);

void collectclasscentroids() {
	//cv::initModule_nonfree();

	//IplImage *img;
	//IplImage *im1;
	Mat img_ini, img;
	int i, j;
	for (j = 1; j <= 6; j++)
	{ if (j == 1||j==2||j==3){
		for (i = 1; i <= 35; i++){



			sprintf(ch, "%s%d%s%d%s", "C:/Users/Nikunj/Documents/Visual Studio 2013/Projects/new/new/trainhand/", j, "(", i, ").jpg");
			//sprintf(ch, "%s", "C:/Users/Nikunj/Documents/Visual Studio 2013/Projects/new/new/trainhand/6(29).jpg");
			cout << j << "(" << i << ")" << endl;
			const char* imageName = ch;
			img_ini = imread(imageName, 1);
			//im1= cvLoadImage("imageName", 0);
			//img_ini = cvarrToMat(im1);
			// img_ini=imread(imageName,1);
			img = pre_processing(img_ini);
			//namedWindow("Display window", WINDOW_NORMAL);
			//imshow("input", img);
			cout << "show?" << endl;
			vector<KeyPoint> keypoint;
			keypoint.reserve(1000000);
			detector->detect(img, keypoint);
			cv::Mat output = img;
			cv::drawKeypoints(img, keypoint, output);
			cv::imwrite("C:/Users/Nikunj/Documents/Visual Studio 2013/Projects/new/new/bow_svm/sift_result.jpg", output);
			//cv::imshow("keypoints", output);


			Mat feat;
			cout << "keypoints" << endl;

			detector->compute(img, keypoint, feat);
			cout << "computed" << endl;

			bowTrainer.add(feat);
			//cout << "no features" << endl;
			cout << j << "(" << i << ")" << endl;

		}
		}

	}
	return;
}



int main(int argc, char* argv[])
{
	/*ofstream fon("C:/Users/Nikunj/Documents/Visual Studio 2013/Projects/new/new/test_svm.txt");
	fon << "actual class: " << " " << "detected class:" << endl;
	VideoCapture capture("C:/Users/Nikunj/Documents/Visual Studio 2013/Projects/new/new/video.mp4");
	cout << "Capture Successful" << endl;
	if (!capture.isOpened()){
		//error in opening the video input
		cerr << "Unable to open video file: " << endl;
		waitKey(0);
	}
	cout << "Definitely Successful" << endl;
	capture.set(CV_CAP_PROP_FRAME_WIDTH, 640);
	capture.set(CV_CAP_PROP_FRAME_HEIGHT, 480);
	cout << "no error in capture set" << endl;
	namedWindow("video current frame", WINDOW_NORMAL);
	moveWindow("video current frame", 0, 0);
	namedWindow("output", WINDOW_NORMAL);
	moveWindow("output", 640, 480);
	keyboard = waitKey(100);
	cout << "Just befor while loop" << endl;
	//read input data. ESC or 'q' for quitting
	while ((char)keyboard != 'q' && (char)keyboard != 27)
	{
		capture.read(frame);
		cout << "no error in reading frame" << endl;
		flip(frame, frame, -1);
		cout << "no flip error" << endl;
		//read the current frame
		if (!capture.read(frame))
		{
			cerr << "Unable to read next frame." << endl;
			waitKey(0);
		}

		imshow("video current frame", frame);
		keyboard = waitKey(1000);
	}*/
	char r;
	cout << "Press a key to start testing" << endl;
	cin >> r;
	int i, j;
	//IplImage *img2;
	Mat img2_ini, img2;
	cout << "Vector quantization..." << endl;
	collectclasscentroids();
	cout << "1 done" << endl;
	vector<Mat> descriptors = bowTrainer.getDescriptors();
	int count = 0;
	for (vector<Mat>::iterator iter = descriptors.begin(); iter != descriptors.end(); iter++)
	{
		count += iter->rows;
	}
	//count = bowTrainer.descriptorsCount();
	cout << "Clustering " << count << " features" << endl;
	//choosing cluster's centroids as dictionary's words
	Mat dictionary = bowTrainer.cluster();
	bowDE.setVocabulary(dictionary);
	cout << "extracting histograms in the form of BOW for each image " << endl;
	Mat labels(0, 1, CV_32SC1);
	Mat trainingData(0, dictionarySize, CV_32FC1);
	//int k=0;
	vector<KeyPoint> keypoint1;
	Mat bowDescriptor1;
//extracting histogram in the form of bow for each image
for (j = 1; j <= 6; j++)
{
	if (j == 1 || j == 2 || j == 3)
	{


		for (i = 1; i <= 35; i++){
			sprintf(ch, "%s%d%s%d%s", "C:/Users/Nikunj/Documents/Visual Studio 2013/Projects/new/new/trainhand/", j, "(", i, ").jpg");
			const char* imageName = ch;
			//img2 = cvLoadImage(imageName, 0);
			img2 = imread(imageName, 1);

			Mat m = pre_processing(img2);

			//Mat m = cvarrToMat(img2);
			detector->detect(m, keypoint1);


			bowDE.compute(m, keypoint1, bowDescriptor1);
			trainingData.push_back(bowDescriptor1);



			labels.push_back(j);

		}
	}
}
cout << labels.size() << endl;
cout << trainingData.size() << endl;
for (int i = 0; i < labels.rows; i++)
	for (int j = 0; j < labels.cols; j++)
		printf("labels(%d, %d) = %d \n", i, j, labels.at<int>(i, j));
//Setting up SVM parameters
Ptr<SVM> svm = SVM::create();
svm->setType(SVM::C_SVC);
//svm->setKernel(SVM::RBF);
svm->setKernel(SVM::LINEAR);
svm->setTermCriteria(TermCriteria(TermCriteria::MAX_ITER, 100, 0.000001));//svm->setTermCriteria(TermCriteria(TermCriteria::MAX_ITER, 100, 1e-6));
svm->setGamma(0.50625000000000009);
svm->setC(312.50000000000000);

printf("%s\n", "Training SVM classifier");

svm->train(trainingData, ROW_SAMPLE, labels);

svm->save("C:/Users/Nikunj/Documents/Visual Studio 2013/Projects/new/new/bow_svm/svm.xml");

cout << "Processing evaluation data..." << endl;


Mat groundTruth(0, 1, CV_32SC1);
Mat evalData(0, dictionarySize, CV_32FC1);
Mat results(0, 1, CV_32FC1);;

//k=0;
vector<KeyPoint> keypoint2;
Mat bowDescriptor2;


ofstream fon("C:/Users/Nikunj/Documents/Visual Studio 2013/Projects/new/new/test_svm.txt");
fon << "actual class: " << " " << "detected class:" << endl;
cout << "Now the main part" << endl;
//VideoCapture capture("C:/Users/Nikunj/Documents/Visual Studio 2013/Projects/new/new/video.mp4");
VideoCapture capture("video.mp4");
cout << "Capture Succesfull" << endl;
if (!capture.isOpened()){
	//error in opening the video input
	cerr << "Unable to open video file: " << endl;
	waitKey(0);
}
cout << "Definitely Successful" << endl;
capture.set(CV_CAP_PROP_FRAME_WIDTH, 640);
capture.set(CV_CAP_PROP_FRAME_HEIGHT, 480);
cout << "no error in capture set" << endl;
namedWindow("video current frame", WINDOW_NORMAL);
moveWindow("video current frame", 0, 0);
namedWindow("output", WINDOW_NORMAL);
moveWindow("output", 640, 480);
//keyboard = waitKey(100);
Mat vidfr;
keyboard = 1;
cout << "Just befor while loop" << endl;
//read input data. ESC or 'q' for quitting
while ((char)keyboard != 'q' && (char)keyboard != 27)
{
	//read the current frame
	if (!capture.read(vidfr))
	{
		cerr << "Unable to read next frame." << endl;
		waitKey(0);
	}
	flip(vidfr, vidfr, -1);
	cout << "no flip error" << endl;
	imshow("video current frame", vidfr);
	keyboard=waitKey(1000);
	if ((char)keyboard == 'y' || (char)keyboard == 'Y')
	{
		Mat m = pre_processing(vidfr);
		detector->detect(m, keypoint2);
		bowDE.compute(m, keypoint2, bowDescriptor2);
		svm->load<SVM>("C:/Users/Nikunj/Documents/Visual Studio 2013/Projects/new/new/bow_svm/svm.xml");
		float response = svm->predict(bowDescriptor2);
		Point org(320, 480);
		if (response == 1)
		{
			putText(vidfr, "ONE", org, 4, 3, Scalar(255, 0, 0), 4, 8);
			imshow("output", vidfr);
			waitKey(1000);
			continue;
		}
		if (response == 2)
		{
			putText(vidfr, "B", org, 4, 3, Scalar(255, 0, 0), 4, 8);
			imshow("output", vidfr);
			waitKey(1000);
			continue;
		}
		if (response == 3)
		{
			putText(vidfr, "O", org, 4, 3, Scalar(255, 0, 0), 4, 8);
			imshow("output", vidfr);
			waitKey(1000);
			continue;
		}

	}
	waitKey(100);
}
waitKey(0);
/*svm->load<SVM>("C:/Users/Nikunj/Documents/Visual Studio 2013/Projects/new/new/bow_svm/svm.xml");
char c;
cout << "Press a key to start testing" << endl;
cin >> c;

for (j = 1; j <= 6; j++)
{
	if (j == 1 || j == 2 || j == 3)
	{

		for (i = 1; i <= 12; i++)
		{

			if (j == 2 && i == 8)
				break;
			sprintf(ch, "%s%d%s%d%s", "C:/Users/Nikunj/Documents/Visual Studio 2013/Projects/new/new/testhand/", j, "(", i, ").jpg");
			cout << j << "(" << i << ")" << endl;
			const char* imageName = ch;
			//img2 = cvLoadImage(imageName, 0);
			img2_ini = imread(imageName, 1);
				Mat m = pre_processing(img2_ini);
				//Mat m = cvarrToMat(img2);
				detector->detect(m, keypoint2);
				bowDE.compute(m, keypoint2, bowDescriptor2);
				svm->load<SVM>("C:/Users/Nikunj/Documents/Visual Studio 2013/Projects/new/new/bow_svm/svm.xml");
				
				evalData.push_back(bowDescriptor2);
				groundTruth.push_back((float)j);

				float response = svm->predict(bowDescriptor2);
				// fon<< response << endl;
				// out.push_back(response);
				fon << "  " << j << "              " << response << endl;

				results.push_back(response);
				Point org(320, 480);
				namedWindow("current frame", WINDOW_NORMAL);
				moveWindow("current frame", 640, 0);
				namedWindow("output", WINDOW_NORMAL);
				moveWindow("output", 640, 480);
				imshow("current frame", img2_ini);
				Mat output;
				
				switch((int)response)
				{
					case 1:
						
						//putText(img2_ini, "ONE", org, 4, 3, Scalar(255, 0, 0), 4, 8);
						output = imread("C:/Users/Nikunj/Documents/Visual Studio 2013/Projects/new/new/1.jpg");
						imshow("output", output);
						waitKey(1000);
			
						break;

					case 2:
						//putText(img2_ini, "Letter B", org, 4, 3, Scalar(255, 0, 0), 4, 8);
						output = imread("C:/Users/Nikunj/Documents/Visual Studio 2013/Projects/new/new/B.jpg");
						imshow("output", output);
						waitKey(1000);
						break;
					case 3:
						//putText(img2_ini, "Letter O", org, 4, 3, Scalar(255, 0, 0), 4, 8);
						output = imread("C:/Users/Nikunj/Documents/Visual Studio 2013/Projects/new/new/O.jpg");
						imshow("output", output);
						waitKey(1000);
						break;
					default:
						cout << "error in switch argument"<<endl;
							waitKey(10000);
							break;

				}
			}
		}
	}
	*/
		cout << "this done" << endl;
		cout << evalData.size() << endl;



		Mat test_mat;
		absdiff(groundTruth, results, test_mat);
		int k = countNonZero(test_mat);
		int size = groundTruth.rows;
		printf("%d %d %f \n", k, size, (float)((size - k) * 100) / size);

		fon.close();
		waitKey(0);


		//calculate the number of unmatched classes
		//  double errorRate = (double) countNonZero(groundTruth- results) / evalData.rows;
		// cout<<"wf";
		// printf("%s%f","Error rate is ",errorRate);

		return 0;

	}
